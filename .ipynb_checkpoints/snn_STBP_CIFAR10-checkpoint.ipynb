{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# -----------------------------------导入数据-----------------------------------\n",
    "trainset = torchvision.datasets.CIFAR10(root='', train=True, download=False, transform=transforms.ToTensor())\n",
    "testset = torchvision.datasets.CIFAR10(root='', train=False, download=False, transform=transforms.ToTensor())\n",
    "\n",
    "batch_size = 100  \n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ------------------------------------------超参数初始化------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "thresh = 0.5                     # 神经元的阈值：neuronal-threshold\n",
    "decay = 0.2                      # 衰减常数：decay-constants\n",
    "lens = 0.5                       # 近似函数的超参数：hyper-parameters of approximate function\n",
    "# num_classes = 10                 # 分类的种类数目：10个\n",
    "learning_rate = 1e-3             # 学习率lr\n",
    "num_epochs = 100                 # 训练次数：最大值100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------定义近似激发函数------------------------------------------\n",
    "class ActFun(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.gt(thresh).float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        temp = abs(input - thresh) < lens\n",
    "        return grad_input * temp.float()\n",
    "    \n",
    "act_fun = ActFun.apply\n",
    "\n",
    "# ------------------------------------------膜电位更新函数------------------------------------------\n",
    "# ops：层      x：输入    mem：膜电位     spike：尖峰电压\n",
    "def mem_update(ops, x, mem, spike):\n",
    "#     print('x:', x.size())\n",
    "#     print('mem:', mem.size())\n",
    "#     print('spike:', spike.size())\n",
    "    \n",
    "    mem = mem * decay * (1. - spike) + ops(x)\n",
    "    spike = act_fun(mem)\n",
    "    return mem, spike\n",
    "\n",
    "# -----------------------------------------衰减学习率lr函数-----------------------------------------\n",
    "# 【说明】每十进制一个新纪元衰减0.1倍的学习速率。\n",
    "def lr_scheduler(optimizer, epoch, init_lr=0.1, lr_decay_epoch=50): \n",
    "    if epoch % lr_decay_epoch == 0 and epoch > 1:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积层Conv2d对应的参数(in_planes, out_planes, stride, padding, kernel_size)\n",
    "cfg_cnn = [(3, 128, 1, 1, 3),\n",
    "           (128, 256, 1, 1, 3),\n",
    "           (256, 512, 1, 1, 3)]\n",
    "# 卷积核\n",
    "cfg_kernel = [32, 16, 8, 4]\n",
    "# fc layer\n",
    "cfg_fc = [512, 10]\n",
    "\n",
    "class SCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SCNN, self).__init__()\n",
    "        in_planes, out_planes, stride, padding, kernel_size = cfg_cnn[0]\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        in_planes, out_planes, stride, padding, kernel_size = cfg_cnn[1]\n",
    "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        in_planes, out_planes, stride, padding, kernel_size = cfg_cnn[2]\n",
    "        self.conv3 = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "        self.fc1 = nn.Linear(cfg_kernel[-1] * cfg_kernel[-1] * cfg_cnn[-1][1], 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, input, time_window = 20):\n",
    "        # -------------------------------1.膜电位mem与尖峰电压spike初始化-------------------------------\n",
    "        c1_mem = c1_spike = torch.zeros(batch_size, cfg_cnn[0][1], cfg_kernel[0], cfg_kernel[0], device=device)   \n",
    "        c2_mem = c2_spike = torch.zeros(batch_size, cfg_cnn[1][1], cfg_kernel[1], cfg_kernel[1], device=device)\n",
    "        c3_mem = c3_spike = torch.zeros(batch_size, cfg_cnn[2][1], cfg_kernel[2], cfg_kernel[2], device=device)\n",
    "        h1_mem = h1_spike = h1_sumspike = torch.zeros(batch_size, cfg_fc[0], device=device)\n",
    "        h2_mem = h2_spike = h2_sumspike = torch.zeros(batch_size, cfg_fc[1], device=device)\n",
    "        \n",
    "        # -------------------------------2.模拟时间-----------------------------------------------------\n",
    "        for step in range(time_window): # 时间窗=20次\n",
    "            # ---------------------------2.1 随机生成数字---> 第一次膜电位更新(conv1)--------------\n",
    "            x = input > torch.rand(input.size(), device=device) # prob. firing\n",
    "            c1_mem, c1_spike = mem_update(self.conv1, x.float(), c1_mem, c1_spike)\n",
    "#             print('-----------------------conv1膜电位更新完成-----------------------')\n",
    "            # ---------------------------2.2 平均池化层 ---> 第二次膜电位更新(conv2)---------------\n",
    "            x = F.avg_pool2d(c1_spike, 2)\n",
    "            c2_mem, c2_spike = mem_update(self.conv2,x, c2_mem,c2_spike)\n",
    "#             print('-----------------------conv2膜电位更新完成-----------------------')\n",
    "            x = F.avg_pool2d(c2_spike, 2)\n",
    "            c3_mem, c3_spike = mem_update(self.conv3,x, c3_mem,c3_spike)\n",
    "            # ---------------------------2.3 平均池化层 ---> 视图展开------------------------------\n",
    "            x = F.avg_pool2d(c3_spike, 2)\n",
    "            x = x.view(batch_size, -1)\n",
    "            # ---------------------------2.4 第三次膜电位更新(fc1) ---> 第四次膜电位更新(fc2)------\n",
    "            h1_mem, h1_spike = mem_update(self.fc1, x, h1_mem, h1_spike)\n",
    "#             print('-----------------------fc1膜电位更新完成-----------------------')\n",
    "            h1_sumspike += h1_spike\n",
    "            h2_mem, h2_spike = mem_update(self.fc2, h1_spike, h2_mem,h2_spike)\n",
    "#             print('-----------------------fc2膜电位更新完成-----------------------')\n",
    "            h2_sumspike += h2_spike\n",
    "\n",
    "        outputs = h2_sumspike / time_window\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [100/500], Train-Loss: 10.64102\n",
      "Time elasped: 56.20961260795593\n",
      "Epoch [1/100], Step [200/500], Train-Loss: 9.16667\n",
      "Time elasped: 112.45132374763489\n",
      "Epoch [1/100], Step [300/500], Train-Loss: 8.63016\n",
      "Time elasped: 168.6838662624359\n",
      "Epoch [1/100], Step [400/500], Train-Loss: 8.12970\n",
      "Time elasped: 224.84655165672302\n",
      "Epoch [1/100], Step [500/500], Train-Loss: 7.65976\n",
      "Time elasped: 281.010272026062\n",
      "0 100  Test-Acc: 51.00000\n",
      "Test Accuracy of the model on the 10000 test images: 38.250 \n",
      "\n",
      "Epoch [2/100], Step [100/500], Train-Loss: 7.37250\n",
      "Time elasped: 56.01802372932434\n",
      "Epoch [2/100], Step [200/500], Train-Loss: 7.22300\n",
      "Time elasped: 112.18670153617859\n",
      "Epoch [2/100], Step [300/500], Train-Loss: 6.83409\n",
      "Time elasped: 168.36246919631958\n",
      "Epoch [2/100], Step [400/500], Train-Loss: 6.87830\n",
      "Time elasped: 224.5375726222992\n",
      "Epoch [2/100], Step [500/500], Train-Loss: 6.67380\n",
      "Time elasped: 280.7149450778961\n",
      "0 100  Test-Acc: 49.00000\n",
      "Test Accuracy of the model on the 10000 test images: 50.410 \n",
      "\n",
      "Epoch [3/100], Step [100/500], Train-Loss: 6.27829\n",
      "Time elasped: 56.0330445766449\n",
      "Epoch [3/100], Step [200/500], Train-Loss: 6.30683\n",
      "Time elasped: 112.2188367843628\n",
      "Epoch [3/100], Step [300/500], Train-Loss: 6.14669\n",
      "Time elasped: 168.40315580368042\n",
      "Epoch [3/100], Step [400/500], Train-Loss: 6.06891\n",
      "Time elasped: 224.5876338481903\n",
      "Epoch [3/100], Step [500/500], Train-Loss: 6.00262\n",
      "Time elasped: 280.77745246887207\n",
      "0 100  Test-Acc: 53.00000\n",
      "Test Accuracy of the model on the 10000 test images: 53.530 \n",
      "\n",
      "Epoch [4/100], Step [100/500], Train-Loss: 5.65969\n",
      "Time elasped: 56.04128456115723\n",
      "Epoch [4/100], Step [200/500], Train-Loss: 5.72651\n",
      "Time elasped: 112.24019289016724\n",
      "Epoch [4/100], Step [300/500], Train-Loss: 5.63128\n",
      "Time elasped: 168.4386055469513\n",
      "Epoch [4/100], Step [400/500], Train-Loss: 5.51842\n",
      "Time elasped: 224.63871264457703\n",
      "Epoch [4/100], Step [500/500], Train-Loss: 5.48463\n",
      "Time elasped: 280.8437042236328\n",
      "0 100  Test-Acc: 59.00000\n",
      "Test Accuracy of the model on the 10000 test images: 57.680 \n",
      "\n",
      "Epoch [5/100], Step [100/500], Train-Loss: 5.11035\n",
      "Time elasped: 56.05359983444214\n",
      "Epoch [5/100], Step [200/500], Train-Loss: 5.07442\n",
      "Time elasped: 112.26516675949097\n",
      "Epoch [5/100], Step [300/500], Train-Loss: 5.17679\n",
      "Time elasped: 168.47196745872498\n",
      "Epoch [5/100], Step [400/500], Train-Loss: 5.01609\n",
      "Time elasped: 224.69583177566528\n",
      "Epoch [5/100], Step [500/500], Train-Loss: 4.97810\n",
      "Time elasped: 280.9135847091675\n",
      "0 100  Test-Acc: 65.00000\n",
      "Test Accuracy of the model on the 10000 test images: 62.350 \n",
      "\n",
      "Epoch [6/100], Step [100/500], Train-Loss: 4.61519\n",
      "Time elasped: 56.06876254081726\n",
      "Epoch [6/100], Step [200/500], Train-Loss: 4.62714\n",
      "Time elasped: 112.27841329574585\n",
      "Epoch [6/100], Step [300/500], Train-Loss: 4.67469\n",
      "Time elasped: 168.48624658584595\n",
      "Epoch [6/100], Step [400/500], Train-Loss: 4.62088\n",
      "Time elasped: 224.69776797294617\n",
      "Epoch [6/100], Step [500/500], Train-Loss: 4.69220\n",
      "Time elasped: 280.95308017730713\n",
      "0 100  Test-Acc: 72.00000\n",
      "Test Accuracy of the model on the 10000 test images: 64.080 \n",
      "\n",
      "Epoch [7/100], Step [100/500], Train-Loss: 4.15638\n",
      "Time elasped: 56.10218095779419\n",
      "Epoch [7/100], Step [200/500], Train-Loss: 4.20844\n",
      "Time elasped: 112.36432528495789\n",
      "Epoch [7/100], Step [300/500], Train-Loss: 4.32934\n",
      "Time elasped: 168.62577605247498\n",
      "Epoch [7/100], Step [400/500], Train-Loss: 4.27259\n",
      "Time elasped: 224.89707398414612\n",
      "Epoch [7/100], Step [500/500], Train-Loss: 4.27868\n",
      "Time elasped: 281.1566152572632\n",
      "0 100  Test-Acc: 69.00000\n",
      "Test Accuracy of the model on the 10000 test images: 65.580 \n",
      "\n",
      "Epoch [8/100], Step [100/500], Train-Loss: 3.85716\n",
      "Time elasped: 56.10997533798218\n",
      "Epoch [8/100], Step [200/500], Train-Loss: 3.81339\n",
      "Time elasped: 112.38323068618774\n",
      "Epoch [8/100], Step [300/500], Train-Loss: 3.79048\n",
      "Time elasped: 168.64559864997864\n",
      "Epoch [8/100], Step [400/500], Train-Loss: 3.91634\n",
      "Time elasped: 224.90501856803894\n",
      "Epoch [8/100], Step [500/500], Train-Loss: 3.97928\n",
      "Time elasped: 281.16823291778564\n",
      "0 100  Test-Acc: 60.00000\n",
      "Test Accuracy of the model on the 10000 test images: 66.700 \n",
      "\n",
      "Epoch [9/100], Step [100/500], Train-Loss: 3.49359\n",
      "Time elasped: 56.110490798950195\n",
      "Epoch [9/100], Step [200/500], Train-Loss: 3.55996\n",
      "Time elasped: 112.38312578201294\n",
      "Epoch [9/100], Step [300/500], Train-Loss: 3.65786\n",
      "Time elasped: 168.65551090240479\n",
      "Epoch [9/100], Step [400/500], Train-Loss: 3.63381\n",
      "Time elasped: 224.92214822769165\n",
      "Epoch [9/100], Step [500/500], Train-Loss: 3.62843\n",
      "Time elasped: 281.1979444026947\n",
      "0 100  Test-Acc: 70.00000\n",
      "Test Accuracy of the model on the 10000 test images: 67.410 \n",
      "\n",
      "Epoch [10/100], Step [100/500], Train-Loss: 3.20029\n",
      "Time elasped: 56.1124849319458\n",
      "Epoch [10/100], Step [200/500], Train-Loss: 3.25555\n",
      "Time elasped: 112.38627052307129\n",
      "Epoch [10/100], Step [300/500], Train-Loss: 3.30053\n",
      "Time elasped: 168.66307830810547\n",
      "Epoch [10/100], Step [400/500], Train-Loss: 3.32156\n",
      "Time elasped: 224.93993425369263\n",
      "Epoch [10/100], Step [500/500], Train-Loss: 3.32418\n",
      "Time elasped: 281.221298456192\n",
      "0 100  Test-Acc: 70.00000\n",
      "Test Accuracy of the model on the 10000 test images: 68.560 \n",
      "\n",
      "Epoch [11/100], Step [100/500], Train-Loss: 2.91253\n",
      "Time elasped: 56.128072023391724\n",
      "Epoch [11/100], Step [200/500], Train-Loss: 2.96940\n",
      "Time elasped: 112.41766905784607\n",
      "Epoch [11/100], Step [300/500], Train-Loss: 3.02729\n",
      "Time elasped: 168.7007873058319\n",
      "Epoch [11/100], Step [400/500], Train-Loss: 3.07145\n",
      "Time elasped: 224.98496341705322\n",
      "Epoch [11/100], Step [500/500], Train-Loss: 3.08303\n",
      "Time elasped: 281.2729682922363\n",
      "0 100  Test-Acc: 66.00000\n",
      "Test Accuracy of the model on the 10000 test images: 68.230 \n",
      "\n",
      "Epoch [12/100], Step [100/500], Train-Loss: 2.68425\n",
      "Time elasped: 56.13485026359558\n",
      "Epoch [12/100], Step [200/500], Train-Loss: 2.72319\n",
      "Time elasped: 112.43068504333496\n",
      "Epoch [12/100], Step [300/500], Train-Loss: 2.73346\n",
      "Time elasped: 168.7260401248932\n",
      "Epoch [12/100], Step [400/500], Train-Loss: 2.85351\n",
      "Time elasped: 225.02093982696533\n",
      "Epoch [12/100], Step [500/500], Train-Loss: 2.91309\n",
      "Time elasped: 281.31198287010193\n",
      "0 100  Test-Acc: 73.00000\n",
      "Test Accuracy of the model on the 10000 test images: 68.290 \n",
      "\n",
      "Epoch [13/100], Step [100/500], Train-Loss: 2.45469\n",
      "Time elasped: 56.13540554046631\n",
      "Epoch [13/100], Step [200/500], Train-Loss: 2.56766\n",
      "Time elasped: 112.4355115890503\n",
      "Epoch [13/100], Step [300/500], Train-Loss: 2.55497\n",
      "Time elasped: 168.72075486183167\n",
      "Epoch [13/100], Step [400/500], Train-Loss: 2.59895\n",
      "Time elasped: 224.9917597770691\n",
      "Epoch [13/100], Step [500/500], Train-Loss: 2.66030\n",
      "Time elasped: 281.2372739315033\n",
      "0 100  Test-Acc: 71.00000\n",
      "Test Accuracy of the model on the 10000 test images: 69.160 \n",
      "\n",
      "Epoch [14/100], Step [100/500], Train-Loss: 2.26042\n",
      "Time elasped: 56.09325981140137\n",
      "Epoch [14/100], Step [200/500], Train-Loss: 2.30133\n",
      "Time elasped: 112.3346221446991\n",
      "Epoch [14/100], Step [300/500], Train-Loss: 2.33675\n",
      "Time elasped: 168.57828426361084\n",
      "Epoch [14/100], Step [400/500], Train-Loss: 2.46102\n",
      "Time elasped: 224.8246293067932\n",
      "Epoch [14/100], Step [500/500], Train-Loss: 2.47191\n",
      "Time elasped: 281.0707402229309\n",
      "0 100  Test-Acc: 70.00000\n",
      "Test Accuracy of the model on the 10000 test images: 69.600 \n",
      "\n",
      "Epoch [15/100], Step [100/500], Train-Loss: 2.03941\n",
      "Time elasped: 56.09773230552673\n",
      "Epoch [15/100], Step [200/500], Train-Loss: 2.12468\n",
      "Time elasped: 112.35415840148926\n",
      "Epoch [15/100], Step [300/500], Train-Loss: 2.19259\n",
      "Time elasped: 168.61674213409424\n",
      "Epoch [15/100], Step [400/500], Train-Loss: 2.27997\n",
      "Time elasped: 224.87901067733765\n",
      "Epoch [15/100], Step [500/500], Train-Loss: 2.28516\n",
      "Time elasped: 281.14088320732117\n",
      "0 100  Test-Acc: 66.00000\n",
      "Test Accuracy of the model on the 10000 test images: 69.510 \n",
      "\n",
      "Epoch [16/100], Step [100/500], Train-Loss: 1.87422\n",
      "Time elasped: 56.11412692070007\n",
      "Epoch [16/100], Step [200/500], Train-Loss: 1.99211\n",
      "Time elasped: 112.42405271530151\n",
      "Epoch [16/100], Step [300/500], Train-Loss: 2.06877\n",
      "Time elasped: 168.75014209747314\n",
      "Epoch [16/100], Step [400/500], Train-Loss: 2.11222\n",
      "Time elasped: 225.06337523460388\n",
      "Epoch [16/100], Step [500/500], Train-Loss: 2.05621\n",
      "Time elasped: 281.3404791355133\n",
      "0 100  Test-Acc: 75.00000\n",
      "Test Accuracy of the model on the 10000 test images: 70.030 \n",
      "\n",
      "Epoch [17/100], Step [100/500], Train-Loss: 1.78640\n",
      "Time elasped: 56.12667155265808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Step [200/500], Train-Loss: 1.83081\n",
      "Time elasped: 112.40415143966675\n",
      "Epoch [17/100], Step [300/500], Train-Loss: 1.83584\n",
      "Time elasped: 168.6774492263794\n",
      "Epoch [17/100], Step [400/500], Train-Loss: 1.92236\n",
      "Time elasped: 224.95103454589844\n",
      "Epoch [17/100], Step [500/500], Train-Loss: 1.98043\n",
      "Time elasped: 281.2248742580414\n",
      "0 100  Test-Acc: 65.00000\n",
      "Test Accuracy of the model on the 10000 test images: 69.760 \n",
      "\n",
      "Epoch [18/100], Step [100/500], Train-Loss: 1.62582\n",
      "Time elasped: 56.12655186653137\n",
      "Epoch [18/100], Step [200/500], Train-Loss: 1.68274\n",
      "Time elasped: 112.4021646976471\n",
      "Epoch [18/100], Step [300/500], Train-Loss: 1.74545\n",
      "Time elasped: 168.67918992042542\n",
      "Epoch [18/100], Step [400/500], Train-Loss: 1.79329\n",
      "Time elasped: 224.9537181854248\n",
      "Epoch [18/100], Step [500/500], Train-Loss: 1.86865\n",
      "Time elasped: 281.2232348918915\n",
      "0 100  Test-Acc: 71.00000\n",
      "Test Accuracy of the model on the 10000 test images: 69.920 \n",
      "\n",
      "Epoch [19/100], Step [100/500], Train-Loss: 1.52278\n",
      "Time elasped: 56.11625361442566\n",
      "Epoch [19/100], Step [200/500], Train-Loss: 1.59444\n",
      "Time elasped: 112.39098906517029\n",
      "Epoch [19/100], Step [300/500], Train-Loss: 1.68539\n",
      "Time elasped: 168.67058277130127\n",
      "Epoch [19/100], Step [400/500], Train-Loss: 1.66972\n",
      "Time elasped: 224.95115494728088\n",
      "Epoch [19/100], Step [500/500], Train-Loss: 1.73880\n",
      "Time elasped: 281.2256133556366\n",
      "0 100  Test-Acc: 72.00000\n",
      "Test Accuracy of the model on the 10000 test images: 69.400 \n",
      "\n",
      "Epoch [20/100], Step [100/500], Train-Loss: 1.39610\n",
      "Time elasped: 56.12639665603638\n",
      "Epoch [20/100], Step [200/500], Train-Loss: 1.52199\n",
      "Time elasped: 112.40968084335327\n",
      "Epoch [20/100], Step [300/500], Train-Loss: 1.51297\n",
      "Time elasped: 168.6956069469452\n",
      "Epoch [20/100], Step [400/500], Train-Loss: 1.56579\n",
      "Time elasped: 224.97857904434204\n",
      "Epoch [20/100], Step [500/500], Train-Loss: 1.61877\n",
      "Time elasped: 281.26124119758606\n",
      "0 100  Test-Acc: 71.00000\n",
      "Test Accuracy of the model on the 10000 test images: 70.140 \n",
      "\n",
      "Epoch [21/100], Step [100/500], Train-Loss: 1.33987\n",
      "Time elasped: 56.139726877212524\n",
      "Epoch [21/100], Step [200/500], Train-Loss: 1.38545\n",
      "Time elasped: 112.42753863334656\n",
      "Epoch [21/100], Step [300/500], Train-Loss: 1.48266\n",
      "Time elasped: 168.7090973854065\n",
      "Epoch [21/100], Step [400/500], Train-Loss: 1.52169\n",
      "Time elasped: 225.0039336681366\n",
      "Epoch [21/100], Step [500/500], Train-Loss: 1.54022\n",
      "Time elasped: 281.29005217552185\n",
      "0 100  Test-Acc: 68.00000\n",
      "Test Accuracy of the model on the 10000 test images: 69.970 \n",
      "\n",
      "Epoch [22/100], Step [100/500], Train-Loss: 1.24231\n",
      "Time elasped: 56.12891364097595\n",
      "Epoch [22/100], Step [200/500], Train-Loss: 1.28356\n",
      "Time elasped: 112.41305708885193\n",
      "Epoch [22/100], Step [300/500], Train-Loss: 1.34343\n",
      "Time elasped: 168.70820379257202\n",
      "Epoch [22/100], Step [400/500], Train-Loss: 1.43510\n",
      "Time elasped: 224.9952368736267\n",
      "Epoch [22/100], Step [500/500], Train-Loss: 1.44217\n",
      "Time elasped: 281.2874267101288\n",
      "0 100  Test-Acc: 74.00000\n",
      "Test Accuracy of the model on the 10000 test images: 69.530 \n",
      "\n",
      "Epoch [23/100], Step [100/500], Train-Loss: 1.18173\n",
      "Time elasped: 56.14446997642517\n",
      "Epoch [23/100], Step [200/500], Train-Loss: 1.21357\n",
      "Time elasped: 112.47005200386047\n",
      "Epoch [23/100], Step [300/500], Train-Loss: 1.28336\n",
      "Time elasped: 168.80005836486816\n",
      "Epoch [23/100], Step [400/500], Train-Loss: 1.31096\n",
      "Time elasped: 225.13285183906555\n",
      "Epoch [23/100], Step [500/500], Train-Loss: 1.35603\n",
      "Time elasped: 281.4633536338806\n",
      "0 100  Test-Acc: 68.00000\n",
      "Test Accuracy of the model on the 10000 test images: 68.990 \n",
      "\n",
      "Epoch [24/100], Step [100/500], Train-Loss: 1.14330\n",
      "Time elasped: 56.182435512542725\n",
      "Epoch [24/100], Step [200/500], Train-Loss: 1.14833\n",
      "Time elasped: 112.51774334907532\n",
      "Epoch [24/100], Step [300/500], Train-Loss: 1.18526\n",
      "Time elasped: 168.85148763656616\n",
      "Epoch [24/100], Step [400/500], Train-Loss: 1.22930\n",
      "Time elasped: 225.19417929649353\n",
      "Epoch [24/100], Step [500/500], Train-Loss: 1.29136\n",
      "Time elasped: 281.52955055236816\n",
      "0 100  Test-Acc: 64.00000\n",
      "Test Accuracy of the model on the 10000 test images: 69.080 \n",
      "\n",
      "Epoch [25/100], Step [100/500], Train-Loss: 1.03425\n",
      "Time elasped: 56.191731214523315\n",
      "Epoch [25/100], Step [200/500], Train-Loss: 1.08827\n",
      "Time elasped: 112.54449796676636\n",
      "Epoch [25/100], Step [300/500], Train-Loss: 1.17317\n",
      "Time elasped: 168.88471794128418\n",
      "Epoch [25/100], Step [400/500], Train-Loss: 1.20048\n",
      "Time elasped: 225.2178201675415\n",
      "Epoch [25/100], Step [500/500], Train-Loss: 1.20639\n",
      "Time elasped: 281.55810165405273\n",
      "0 100  Test-Acc: 70.00000\n",
      "Test Accuracy of the model on the 10000 test images: 69.350 \n",
      "\n",
      "Epoch [26/100], Step [100/500], Train-Loss: 0.98883\n",
      "Time elasped: 56.197083711624146\n",
      "Epoch [26/100], Step [200/500], Train-Loss: 1.00965\n",
      "Time elasped: 112.54228711128235\n",
      "Epoch [26/100], Step [300/500], Train-Loss: 1.09720\n",
      "Time elasped: 168.89324402809143\n",
      "Epoch [26/100], Step [400/500], Train-Loss: 1.08726\n",
      "Time elasped: 225.2425515651703\n",
      "Epoch [26/100], Step [500/500], Train-Loss: 1.12373\n",
      "Time elasped: 281.5970947742462\n",
      "0 100  Test-Acc: 71.00000\n",
      "Test Accuracy of the model on the 10000 test images: 69.500 \n",
      "\n",
      "Epoch [27/100], Step [100/500], Train-Loss: 0.95903\n",
      "Time elasped: 56.201926708221436\n",
      "Epoch [27/100], Step [200/500], Train-Loss: 0.96821\n",
      "Time elasped: 112.54938650131226\n",
      "Epoch [27/100], Step [300/500], Train-Loss: 1.02623\n",
      "Time elasped: 168.89274144172668\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# ------------------------------------------相关参数初始化------------------------------------------\n",
    "best_acc = 0                    # 最佳准确率acc\n",
    "start_epoch = 0                 # 循环epoch起始点\n",
    "epoch_record = list([])\n",
    "train_loss_record = list([])\n",
    "test_acc_record = list([])           # 历史记录：准确率acc\n",
    "test_loss_record = list([])\n",
    "\n",
    "# ------------------------------------------SCNN网络初始化------------------------------------------\n",
    "snn = SCNN()\n",
    "snn.to(device)\n",
    "criterion = nn.MSELoss()    # 均方误差MSE\n",
    "optimizer = torch.optim.Adam(snn.parameters(), lr=learning_rate)   # 动量类型的梯度下降法\n",
    "\n",
    "# ---------------------------------------------模型训练---------------------------------------------\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    start_time = time.time()  \n",
    "    \n",
    "    # ----------------------------------------------1.利用【训练集】进行训练----------------------------------------------\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # ---------------------------1.1 梯度初始化-------------------------------------\n",
    "        snn.zero_grad()        \n",
    "        optimizer.zero_grad()   \n",
    "        # ---------------------------1.2 将数据转换成模型可以使用的类型-----------------\n",
    "        images = images.float().to(device)\n",
    "        labels_ = torch.zeros(batch_size, 10).scatter_(1, labels.view(-1, 1), 1)\n",
    "        # ---------------------------1.3 将数据载入模型，获取输出-----------------------\n",
    "        outputs = snn(images)\n",
    "        # ---------------------------1.4 计算损失---------------------------------------\n",
    "        loss = criterion(outputs.cpu(), labels_)\n",
    "        running_loss += loss.item()\n",
    "        train_loss += loss.item()\n",
    "        # ---------------------------1.5 反向传播+更新权重------------------------------\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # ---------------------------1.6 打印批处理的结果-------------------------------\n",
    "        # 【说明】因为训练集60000个，每次批处理100个数据；所以每次epoch需要进行600次批处理，而我们需要每进行100次批处理打印一下结果。\n",
    "        if (i+1)%100 == 0:\n",
    "             print ('Epoch [%d/%d], Step [%d/%d], Train-Loss: %.5f'\n",
    "                    %(epoch+1, num_epochs, i+1, len(trainset)//batch_size,running_loss ))\n",
    "             running_loss = 0\n",
    "             print('Time elasped:', time.time()-start_time)   \n",
    "    \n",
    "    train_loss_record.append(train_loss)\n",
    "    train_loss = 0\n",
    "    # 初始化参数\n",
    "    correct = 0   # 统计：下面进行测试中正确的个数\n",
    "    total = 0     # 统计：下面进行测试中样本的总个数\n",
    "    # 调整学习率\n",
    "    optimizer = lr_scheduler(optimizer, epoch, learning_rate, 40)    \n",
    "    \n",
    "    \n",
    "    # ----------------------------------------------2.利用【测试集】进行测试----------------------------------------------\n",
    "    # 100*100=10000张\n",
    "    # with torch.no_grad()或者@torch.no_grad()中的数据不需要计算梯度，也不会进行反向传播，（torch.no_grad()是新版本pytorch中volatile的替代）\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            # ---------------------------2.1 梯度初始化-------------------------------------\n",
    "            optimizer.zero_grad()\n",
    "            # ---------------------------2.2 将数据转换成模型可以使用的类型-----------------\n",
    "            inputs = inputs.to(device)\n",
    "            labels_ = torch.zeros(batch_size, 10).scatter_(1, targets.view(-1, 1), 1)\n",
    "            # ---------------------------2.3 将数据载入模型，获取输出-----------------------\n",
    "            outputs = snn(inputs)\n",
    "            # ---------------------------2.4 计算损失---------------------------------------\n",
    "            loss = criterion(outputs.cpu(), labels_)\n",
    "            test_loss += loss.item()\n",
    "            # ---------------------------2.5 统计样本数量及正确个数-------------------------\n",
    "            _, predicted = outputs.cpu().max(1)\n",
    "            total += float(targets.size(0))\n",
    "            correct += float(predicted.eq(targets).sum().item())\n",
    "            # ---------------------计算第0次batch_idx中0~100测试集的正确率acc---------------\n",
    "            if batch_idx %100 ==0:\n",
    "                test_acc = 100. * float(correct) / float(total)\n",
    "                print(batch_idx, len(test_loader),' Test-Acc: %.5f' % test_acc)\n",
    "                \n",
    "    test_acc = 100 * correct / total        \n",
    "    print('Test Accuracy of the model on the 10000 test images: %.3f' % test_acc,'\\n')\n",
    "    test_acc_record.append(test_acc)                      # 记录每一轮epoch中在测试集中的准确度\n",
    "    test_loss_record.append(test_loss)\n",
    "    test_loss = 0\n",
    "    \n",
    "    epoch_record.append(epoch)\n",
    "    history_dic = {\n",
    "        'epoch_list': epoch_record,\n",
    "        'train_loss_list': train_loss_record,\n",
    "        'test_acc_list': test_acc_record,\n",
    "        'test_loss_list': test_loss_record\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 可视化：准确率accuracy  acc_record\n",
    "plt.plot(range(1,len(history_dic['train_loss_list'])+1),history_dic['train_loss_list'],'r',label = 'train_loss_list')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,len(history_dic['test_loss_list'])+1),history_dic['test_loss_list'],'b',label = 'test_loss_list')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,len(history_dic['test_acc_list'])+1),history_dic['test_acc_list'],'g',label = 'test_acc_list')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
